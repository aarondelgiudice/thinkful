{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building your first model: Naive Bayes\n",
    "Unit 2 / Lesson 2\n",
    "\n",
    "You're ready to build your first model.\n",
    "In this lesson we'll introduce __Naive Bayes__, a modeling technique built off of Bayes' Rule.\n",
    "\n",
    "Specifically, in this lesson we'll cover:\n",
    "\n",
    "- The difference between classifiers and regressions\n",
    "- What is a Naive Bayes classifier?\n",
    "- Choosing between types of Naive Bayes models\n",
    "- A guided example of how to build this type of model using SciKit Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression vs classification\n",
    "Unit 2 / Lesson 2 / Assignment 1\n",
    "\n",
    "When building a model, the first question to ask is: \"What kind of model do I need to build?\"\n",
    "There are many many possible answers to that question, so it's worth working from the top down.\n",
    "We've already said that this Unit will be about _supervised learning_ and covered a little bit about what that means.\n",
    "Within _supervised learning_ there are two main groups: __classification__ and __regression__. \n",
    "\n",
    "This assignment will focus on the distinction between those two categories and how you choose which kind of model you want to build."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "Let's discuss __classification models__ first.\n",
    "When building a _supervised model_, there is always some kind of outcome we're interested in.\n",
    "What kind of variable that is informs what kind model we are going to build.\n",
    "\n",
    "For a __classification model__, that variable will be _categorical_.\n",
    "This means that the variable only takes discrete values from within a specified set.\n",
    "Simple versions of that set could look something like {yes, no} or {heads, tails}.\n",
    "The outcomes could also contain more than two values such as {high, medium, low} or {buy, rent, no purchase}.\n",
    "Almost anything that can be discretely counted and labeled can be considered a categorical variable.\n",
    "In the earlier assignment on feature engineering we discussed the three kinds of categorical variables: ordinal, interval, and ratio variables.\n",
    "\n",
    "So, given this, the outcome of a classifier is typically one of two things.\n",
    "It will either assign a category to a given test observation or it will assign a probability of each category.\n",
    "This means say if the potential outcomes were {yes, no}, for a given test row the output of a classifier would either be {yes} or {no} or some probability measure for each such as {.2, .8}.\n",
    "\n",
    "It is important to note that with a __classifier__, the only outcomes that will be seen as possible have to be in the training set.\n",
    "So if your test set has a value for the outcome variable that was not in the training set it will not be able to predict it correctly.\n",
    "One example could be if you were trying to predict the show that someone would watch on a movie website and a new movie was released. If that movie isn't in the training set you can't predict if people will watch it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression\n",
    "\n",
    "In contrast to _classification_, __regression models__ have a continuous outcome variable.\n",
    "As such __regressions__ can output either on a _bounded or unbounded number line_.\n",
    "That also implies a relationship between the variables.\n",
    "This simply means something like 3 is greater than 2 is greater than 1, and the intermediate values imply just that, they are between each other.\n",
    "\n",
    "Example variables that would work for regression would be something like amount spent which could range from 0 to some potentially very large observable max, or temperature which ranges from absolute zero to again observably high (though any model would likely concentrate output in a more specific region).\n",
    "Many regression techniques can give predictions even beyond observed maxima and minima, while others are more bounded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Think Like a Data Scientist\n",
    "\n",
    "So what if the outcome you're interested in is the number of cars owned {0, 1, 2, 3, 4, 5} and you've never seen someone with more than 5.\n",
    "Should you use __regression__ or __classification__?\n",
    "\n",
    "The fact is you could use either.\n",
    "If you use __classification__ then for each observation you're only going to be able to evaluate the likelihood of each given value.\n",
    "Each outcome level will be treated discretely and the relationship between them is not predefined.\n",
    "\n",
    "If you use __regression__ you're going to find their most likely place along a continuous line, without necessarily even having bounds at zero or 5.\n",
    "Each approach has its advantages, and which one you'll want to use will depend on how you want to use the output.\n",
    "\n",
    "Keep in mind a classifier generally does not average these outcomes for you, so if you're just getting a single output it will give you the most likely outcome, not the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
