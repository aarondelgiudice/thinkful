{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Evaluation and Cross Validation\n",
    "\n",
    "Unit 2 / Lesson 3 / Assignment 3\n",
    "\n",
    "It's come time to address another potential source of error in our models: __overfitting__.\n",
    "__Overfitting__ is when your model is _so excessively complex that it starts to catch random noise_ instead of _describing the true underlying relationships_.\n",
    "\n",
    "This is typically manifested with a model that _evaluates as more accurate than it really is_.\n",
    "In most situations you shouldn't be able to build a perfect model, some error is to be expected.\n",
    "__Overfitting__ is extremely common and easy to do, but there are ways to guard against it.\n",
    "The main way is through how you evaluate your model.\n",
    "\n",
    "Thus far we've been using our training data to evaluate our model.\n",
    "By this we mean that we've used the same data to train the model and to see how well the model is doing.\n",
    "When you think about it, some of the danger of that approach may become apparent.\n",
    "If we create a very elaborate model it will pick up on the nuances of the data that are just from random noise.\n",
    "If we evaluate the model on the training data, that ability to pick up noise will be returned as accuracy.\n",
    "In reality, this isn't the case and doesn't depict how we'd really want to evaluate a model.\n",
    "Generally we don't care about predicting things we already know.\n",
    "We care about other data, new information, or other situations.\n",
    "This is why testing with training data really isn't what we want to do. \n",
    "\n",
    "But if that's the case, what can we do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holdout Groups\n",
    "\n",
    "The simplest way to combat overfitting is with a **holdout group** (or sometimes \"holdback group\").\n",
    "All this means is that you do not include all of your data in your training set, instead reserving some of it exclusively for testing.\n",
    "While there is a cost to having less training data, your evaluation will be far more reliable.\n",
    "\n",
    "When directly comparing two models that are based on different techniques or different specifications, this __holdout method__ combats __overfitting__.\n",
    "Overfit models will see a drop in success rate outside of their training data, and so their performance will not be artificially inflated as it would be if you trained and validated your model using the whole data set.\n",
    "This is because they got really good at matching the patterns within the data they were trained with, but didn't actually learn the things that matter but random noise.\n",
    "When they try to match that random noise on new data their accuracy suffers.\n",
    "\n",
    "How much data you choose to keep in a holdout is really up to you and depends on how much and what kind of data you have to begin with as well as what kind of model you're training.\n",
    "You should check and see how much variance your model has as you add more data as well as how much data it would take to maintain a reasonably representative test sample.\n",
    "It is, however, a balance.\n",
    "30% is a common starting point, but really anything from 50% to 1% of the original dataset could be reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>message</th>\n",
       "      <th>click</th>\n",
       "      <th>offer</th>\n",
       "      <th>winner</th>\n",
       "      <th>buy</th>\n",
       "      <th>free</th>\n",
       "      <th>cash</th>\n",
       "      <th>urgent</th>\n",
       "      <th>allcaps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    spam                                            message  click  offer  \\\n",
       "0  False  Go until jurong point, crazy.. Available only ...  False  False   \n",
       "1  False                      Ok lar... Joking wif u oni...  False  False   \n",
       "2   True  Free entry in 2 a wkly comp to win FA Cup fina...  False  False   \n",
       "3  False  U dun say so early hor... U c already then say...  False  False   \n",
       "4  False  Nah I don't think he goes to usf, he lives aro...  False  False   \n",
       "\n",
       "   winner    buy   free   cash  urgent  allcaps  \n",
       "0   False  False  False  False   False    False  \n",
       "1   False  False  False  False   False    False  \n",
       "2   False  False  False  False   False    False  \n",
       "3   False  False  False  False   False    False  \n",
       "4   False  False  False  False   False    False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab and process the raw data\n",
    "PATH = (\"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "             \"master/sms_spam_collection/SMSSpamCollection\"\n",
    "            )\n",
    "\n",
    "sms_raw = pd.read_csv(PATH, delimiter= '\\t', header=None)\n",
    "sms_raw.columns = ['spam', 'message']\n",
    "\n",
    "# Enumerate our spammy keywords.\n",
    "keywords = ['click', 'offer', 'winner', 'buy', 'free', 'cash', 'urgent']\n",
    "\n",
    "for key in keywords:\n",
    "    sms_raw[str(key)] = sms_raw.message.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    ")\n",
    "\n",
    "sms_raw['allcaps'] = sms_raw.message.str.isupper()\n",
    "sms_raw['spam'] = (sms_raw['spam'] == 'spam')\n",
    "\n",
    "sms_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 5572: 604\n",
      "Model accuracy: 89.16008614501077 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4770,   55],\n",
       "       [ 549,  198]], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sms_raw[keywords + ['allcaps']]\n",
    "target = sms_raw['spam']\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "y_pred = bnb.fit(data, target).predict(data)\n",
    "\n",
    "# display results\n",
    "print('Number of mislabeled points out of a total {}: {}'.format(\n",
    "    data.shape[0], (target != y_pred).sum()\n",
    "))\n",
    "print('Model accuracy:',\n",
    "      ((data.shape[0] - (target != y_pred).sum()) / data.shape[0]*100),\n",
    "      '%')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(target, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with 20% holdout: 0.884304932735426\n",
      "testing on sample: 0.8916008614501076\n"
     ]
    }
   ],
   "source": [
    "# Test your model with different holdout groups.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "\n",
    "print('with 20% holdout: ' +\n",
    "      str(bnb.fit(X_train, Y_train).score(X_test, Y_test)) )\n",
    "print('testing on sample: ' + \n",
    "     str(bnb.fit(data, target).score(data,target)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These scores look consistent, which means it _doesn't seem like our model is __overfitting___.\n",
    "Part of the reason for that is that it's so simple (more on that in a bit).\n",
    "We should look and see if any other issues are lurking here.\n",
    "Let's try a more robust evaluation technique, __cross validation__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "\n",
    "__Cross validation__ is a more robust version of __holdout groups__.\n",
    "Instead of creating just one holdout, you create several.\n",
    "\n",
    "The way it works is this: start by breaking up your data into several equally sized pieces, or __folds__.\n",
    "Let's say you make _x_ folds.\n",
    "You then go through the training and testing process _x_ times, each time with a different fold held out from the training data and used as the test set.\n",
    "\n",
    "The number of folds you create is up to you, but it will depend on how much data you want in your testing set.\n",
    "At its most extreme, you're creating the same number of folds as you have observations in your data set.\n",
    "This kind of cross validation has a special name: __Leave One Out__. Leave one out is useful if you're worried about single observations skewing your model, whereas large folds combat more general overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89784946, 0.89426523, 0.89426523, 0.890681  , 0.89605735,\n",
       "       0.89048474, 0.88150808, 0.89028777, 0.88489209, 0.89568345])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(bnb, data, target, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The array that `cross_val_score` returns is a series of accuracy scores with a different __hold out group__ each time.\n",
    "If our model is __overfitting__ at a variable amount, those scores will fluctuate.\n",
    "Instead, ours are relatively consistent.\n",
    "\n",
    "Above we used the SKLearn built in functions for both of these kinds of cross validation, the documentation for which can be found [here](http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators-with-stratification-based-on-class-labels).\n",
    "However, the outputs from that are somewhat limited.\n",
    "By default it uses the `score` method.\n",
    "You can adjust what is returned, but you don't get all of the error types or outputs you may be interested in.\n",
    "That's why it's not uncommon for people to code up their own cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implement your own cross validation with your spam model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's a good score?\n",
    "\n",
    "When we're looking at this model, we've been getting accuracy scores around 89%.\n",
    "Intuitively that seems like a pretty good score, but in the start of this lesson we mentioned different kinds of error.\n",
    "We also mentioned __class imbalance__.\n",
    "Both of these things are at play here.\n",
    "Using the topics we introduced earlier in this lesson, try to do a more in depth evaluation of the model looking at the kind of errors we're generating and what accuracy we'd get if we just randomly guessed.\n",
    "\n",
    "You may want to use what's known as a [confusion matrix](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) to show different kinds of errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4770   55]\n",
      " [ 549  198]]\n"
     ]
    }
   ],
   "source": [
    "# Perform your additional evaluation here.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cf = confusion_matrix(target, y_pred)\n",
    "print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549 false positives identified something as spam that is not\n",
      "55 false negatives identified something as not spam when it is\n",
      "\n",
      "Sensitivity: 26.506024096385545 %\n",
      "198 percent of total 747 positives correctly identified\n",
      "\n",
      "Specificity: 98.860103626943 %\n",
      "4770 percent of total 4825 negatives correctly identified\n"
     ]
    }
   ],
   "source": [
    "print('{} false positives identified something as spam that is not'\n",
    "      .format(cf[1,0]))\n",
    "print('{} false negatives identified something as not spam when it is'\n",
    "      .format(cf[0,1]))\n",
    "print()\n",
    "\n",
    "sen = (cf[1,1]/cf[1].sum()*100)\n",
    "print('Sensitivity:', sen, '%')\n",
    "print('{} percent of total {} positives correctly identified'\n",
    "      .format(cf[1,1], cf[1].sum() ))\n",
    "print()\n",
    "\n",
    "spe = (cf[0,0]/cf[0].sum()*100)\n",
    "print('Specificity:', spe, '%')\n",
    "print('{} percent of total {} negatives correctly identified'\n",
    "      .format(cf[0,0], cf[0].sum() ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking like a Data Scientist\n",
    "\n",
    "How you choose to validate your model in real life will depend upon the kind of data you're working with and the kinds of concerns you have about the model's performance.\n",
    "Remember, your model is trained to fit the data you feed it, so if the situation changes your model will become less accurate.\n",
    "\n",
    "For example, if there are seasonal changes to your observed variable but you only train on one month's data, you're going to have a problem.\n",
    "You could test that by seeing how accurate your model is with a specific time period as your __holdout__, rather than a random sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting and Naive Bayes\n",
    "\n",
    "__Overfitting__ is always possible, but some models are more susceptible to it than others.\n",
    "__Naive Bayes__ is actually pretty good at avoiding __overfitting__.\n",
    "This is largely because the assumptions are so simple, particularly the assumed independence between any two independent variables.\n",
    "One of the sources of __overfitting__ is when a model tries to map complex interactions between variables that aren't really there or significant.\n",
    "__Naive Bayes__ cannot do this because it assumes they are all independent and therefore not interacting.\n",
    "It's a nice characteristic at times, but it does mean it doesn't take into account how your features affect each other.\n",
    "\n",
    "One final note on our models here.\n",
    "They weren't __overfitting__, but they weren't telling us much either.\n",
    "They were just barely more accurate than the dominant class.\n",
    "\n",
    "Discuss with your mentor why that is and what you could do to improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
