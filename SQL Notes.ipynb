{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Databases\n",
    "\n",
    "Databases are typically organized in layers that have a broader application based on the context.\n",
    "This is sometimes called the persistance layer.\n",
    "\n",
    "Often the application stack of databases fits into one three categories: operations, storage, or analytics.\n",
    "An operation service delivers the user experience or product\n",
    "Operational services consist of serveral parts, such as a server and client-side application code\n",
    "In a social media app, the operational service would be the client-side application code users run in their browser\n",
    "such an app would keep track of all users, store their information (name, geolocation, etc.), and their interactions other users (messages, etc.).\n",
    "Operation services leverage databases to store information. Databases are serperate from but dependent on the operational system.\n",
    "\n",
    "Databases are typically comprised of a series of tables, each with their own schema and a number of records (rows).\n",
    "Table data is organized into columns, each with a name and data type, this is called the schema.\n",
    "The schema will changed based on the table and developers needs over time.\n",
    "Changing a schema requires data to be migrated or systematically updated to support the changed schema.\n",
    "Each record must conform to the schema and ideally will have an entry in every field.\n",
    "Without an entry, a record will have a null, n/a, or blank field.\n",
    "Raw tables contain simple, unprocessed data.\n",
    "This data will closely resemble the data originally generated by the operations service.\n",
    "Processed tables will contain data that has been transformed in some way to make it more readable and usable.\n",
    "Roll-up tables will take data and aggregate. They are a type of processed table.\n",
    "\n",
    "Raw data is not inherently valuable, instead the values comes from the insights we gain from applying analytics to data.\n",
    "To analyze data, we use database queries to access data.\n",
    "Queries are requests for specific parts of the databases. For example the name and email address of a user with a specific ID.\n",
    "For relational databases, SQL is the common language to create, retrieve, update, and delete database records.\n",
    "\n",
    "There are many different forms of SQL (PostgreSQL, MySQL, SQLite, HiveQL) so make sure when looking up SQL language features, you're looking at the documentation for the particular database you're using.\n",
    "\n",
    "When querying, remember that SQL views the world in rows, so we'll want to work with attributes that exist that row-level.\n",
    "We can do grouping such as sums and averages, but that must be done with row level characteristics.\n",
    "\n",
    "Tables in a database will also have an index and querying an index will be must faster than querying an entire table.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Basics\n",
    "\n",
    "To model and analyze data, you first need the RIGHT data. To access that, we use database queries. These will be the foundation of the work we do as data scienctists.\n",
    "\n",
    "\n",
    "the CREATE clause\n",
    "A database schema is a formal statement in SQL about how the columns and tables of a database are set up. A database contains one or more schemas which in turn contain tables. Schemas also contain other types of objects, such as data types, functions, and operators.\n",
    "\n",
    "To create a new table in a database, use the CREATE TABLE clause:\n",
    "    CREATE TABLE table_name(\n",
    "     column_name_1 TYPE column_constraint,\n",
    "     column_name_2 TYPE,\n",
    "     column_name_3 TYPE\n",
    "    );\n",
    "\n",
    "Specify the table name after the CREATE TABLE clause. To avoid potential issues, use these conventions when creating tables:\n",
    "    use lowercase when creating table names\n",
    "    do not use spaces, instead use underscores ( _ )\n",
    "    Postgres has some quirks with naming indentifiers (such as table names) in quotes and non-quotes. To avoid this, don't use double quotes when naming tables\n",
    "    using meaningful and consistent table names\n",
    "\n",
    "Lines after CREATE TABLE table_name configure the columns. Each column has a name and type. In the example above, replace TYPE with a valid type such as TEXT or INTEGER. It's also possible to add constraints to a column, such as making values in a column unique to a table or prohibiting null values.\n",
    "\n",
    "The individual column creation lines in our SQL statement get separated by a comma and ideally a new line to aid readability.\n",
    "\n",
    "PostgreSQL includes a large set of built-in data types and it's even possible to define your own datatype.\n",
    "\n",
    "\n",
    "The SELECT and FROM clause\n",
    "The SELECT clause retrieves rows of data from a table. The SELECT clause clause indicates a SELECT statement and a FROM statement.\n",
    "\n",
    "We can query our data to retrieve all rows and columns from someTable:\n",
    "    SELECT * FROM someTable;\n",
    "\n",
    "We can be more specific about the columns we want to retrieve:\n",
    "    SELECT col1, col2, anotherColumn FROM someTable;\n",
    "\n",
    "We can select the station names from our stations.sql data:\n",
    "    SELECT name FROM stations;\n",
    "\n",
    "We can also ALIAS columns. Aliasing is refering to the underlying database column by a different name in our query:\n",
    "    SELECT name station_name FROM stations;\n",
    "\n",
    "this can also be written as:\n",
    "    SELECT name AS station_name FROM stations;\n",
    "\n",
    "Column aliasing is useful when you need to query across multiple tables that contain common column names. For example, two tables may have a column named 'id' and we need the 'id' values from both tables.\n",
    "\n",
    "\n",
    "Filtering with WHERE\n",
    "We can use the WHERE clause to only select rows meeting a particular condition. For example, we want to retrieve all orders that match a specific customer id, or banking transactions on a specific date.\n",
    "\n",
    "The WHERE clause allows us to specify a set of conditions.\n",
    "\n",
    "The LIKE operator can use pattern matching when analyzing string data\n",
    "\n",
    "The BETWEEN operator can be used to check if a value is between a set of supplied values.\n",
    "\n",
    "Last but not least, the AND and OR operators let us link together filter conditions in a WHERE block.\n",
    "\n",
    "\n",
    "Ordering with ORDER\n",
    "the ORDER BY clause allows us to control the order that our data is returned. You can order by one or more columns and specify ascending or descending order.\n",
    "\n",
    "In the following example, we retrieve trip ID and start date for each trip record in our trips table where the bike_id columns value is over 27 and the zip_code column's value is 94107. In the ORDER BY clause we specify that we want the data sorted by the duration column in descending order:\n",
    "\n",
    "    SELECT \n",
    "        trip_id, start_date\n",
    "    FROM \n",
    "        trips\n",
    "    WHERE\n",
    "        bike_id = 27 AND\n",
    "        zip_code = 94107\n",
    "    ORDER BY duration DESC;\n",
    "    -- These are comments, by the way. Use two dashes for single-line comments.\n",
    "\n",
    "Note that our conditions here rely on the fact that the columns bike_id and zip_code are numeric. To match strings, you have to enclose the string text in 'single quotes'. In these cases, the LIKE operator can also be useful.\n",
    "\n",
    "Here's how the query would look if we wanted to add a constraint such as subscriber type, which is a string:\n",
    "\n",
    "    SELECT\n",
    "        trip_id,\n",
    "        start_date\n",
    "    FROM\n",
    "        trips\n",
    "    WHERE\n",
    "        bike_id = 27 AND\n",
    "        subscriber_type LIKE 'Customer'\n",
    "    ORDER BY duration DESC;\n",
    "    --unlike python strings in SQL must use single quotes.\n",
    "\n",
    "Make sure to always use single quotes with strings in SQL. Using double quotes is a common mistake that leads to fun errors.\n",
    "\n",
    "\n",
    "Limiting with LIMIT\n",
    "We can use the LIMIT clause to limit the number of results returned by a query.\n",
    "\n",
    "Let's limit our query to retrieve only the three longest trips:\n",
    "\n",
    "    SELECT\n",
    "        trip_id,\n",
    "        start_date\n",
    "    FROM\n",
    "        trips\n",
    "    WHERE \n",
    "        bike_id = 27 AND\n",
    "        subscriber_type LIKE 'Customer'\n",
    "    ORDER BY duration DESC\n",
    "    LIMIT 3;\n",
    "    \n",
    "\n",
    "Formatting Conventions\n",
    "SQL is one of the most readable computer languages and sticking to a few conventions will ensure readability:\n",
    "\n",
    "    1. Put each column name in a select clause on its own line, with one level of indentation from the preceding line.\n",
    "    2. Follow the same indentation logic for FROM, WHERE, and ORDER BY blocks, giving each element its own line.\n",
    "    3. Similarly, each clause gets its own line.\n",
    "    4. Use all caps for clauses, function names, and the like.\n",
    "    5. Use the actual case of the column/table name when referring to column and table names.\n",
    "    6. Be consistent in your own use of casing, but recognize that SQL is not case sensitive, and it doesn't actually care about tabs and newlines.\n",
    "\n",
    "Here's a good example of what not to do:\n",
    "select trip_id, start_date from trips where bike_id=27 and zip_code=94107 order by duration desc limit 3;\n",
    "\n",
    "The above example will execute, but it will be impossible to debug as our queries get bigger.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Drills\n",
    "\n",
    "- Write SQL queries to return:\n",
    "\n",
    "\n",
    "- The IDs and durations for all trips of duration greater than 500, ordered by duration.\n",
    "\n",
    "\n",
    "- Every column of the stations table for station id 84.\n",
    "\n",
    "\n",
    "- The min temperatures of all the occurrences of rain in zip 94301.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregating and Grouping\n",
    "Queries can be made more powerful by grouping and aggregating. Grouping will collect database records according to some criteria. Aggregating is applying one of many possible aggregating operation on a query. Examples of aggregating operations are getting the max value in a column or averaging values in a certain range.\n",
    "\n",
    "For example, you have a table that records zip codes, estimated home prices, last sold amount, and days on the market for most the recent sales. This query would group by zip code and return the average estimated home price and the max value for days on the market for the most recent sale:\n",
    "\n",
    "    SELECT zipcode, AVG(estimated_home_price), MAX(days_on_market)\n",
    "    FROM recent_sales\n",
    "    GROUP BY zipcode;\n",
    "\n",
    "\n",
    "GROUP BY\n",
    "The GROUP BY clause comes after the WHERE clause and before the ORDER BY clause. Without any aggregation, grouping simply gets ride of duplicates. So all columns included in your SELECT statement must also be included in your GROUP BY statement. Here's an example:\n",
    "\n",
    "    SELECT\n",
    "        city\n",
    "     FROM\n",
    "        stations\n",
    "    GROUP BY city;\n",
    "\n",
    "This will return all unique city names in the station table. We can also use numbers rather than names to reference columns:\n",
    "\n",
    "    SELECT\n",
    "        city\n",
    "     FROM\n",
    "        stations\n",
    "    GROUP BY 1;\n",
    "    --this will group by the first column\n",
    "\n",
    "When grouping over multiple columns the data is reduced to unique values or combinations of values generated by the GROUP BY statement. Each unique group item gets a row in the output.\n",
    "\n",
    "\n",
    "Aggregators\n",
    "Aggregators collect values and return a single value. This could be things like max/min or averages.\n",
    "\n",
    "Let's try an example, query for the mean latitude and longitude for stations in each city, as well as station count:\n",
    "\n",
    "    SELECT\n",
    "        city,\n",
    "        AVG(lat) as latitude,\n",
    "        AVG(long) as longitude,\n",
    "        COUNT(*) as station_count\n",
    "    FROM\n",
    "        stations\n",
    "    GROUP by 1;\n",
    "    -- We exclude columns that use aggregate functions from the group by\n",
    "    -- clause, which is why we're only grouping by the city column.\n",
    "\n",
    "Note that when working with aggregators, the name of the column of your output defaults to the function used to generate it. The function names usually aren't very descriptive, so renaming columns is particularly useful.\n",
    "\n",
    "AVG will take the average of all of the values in the specified column with a given value in the grouped columns.\n",
    "COUNT(*) will count the number of rows with the given value in the grouped columns.\n",
    "\n",
    "Note that when using aggregate functions, every column in the query that doesn't use an aggregate function needs to be in the GROUP BY clause.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beyond data selection, you could use Python to accomplish everything we're learning to do with SQL. We could just use SQL to create CSVs that we use with Pythin. How do we know when to use SQL and when to use Python?\n",
    "\n",
    "The first thing to consider is the size of the data. SQL is much better and faster at processing large data and the production database server is probably much beefier than your laptop running Python (there are some exceptions to this like using a distributed Python framework like Spark).\n",
    "\n",
    "SQL queries are also much lower weight to transfer across a network than a Python script plus a CSV or JSON dataset. Since SQL queries directly access the database they are also always accessing current data. SQL output is also easy to pipe into a Python environment.\n",
    "\n",
    "Ultimately, home much to use SQL will will depend on the resources available, personal preference, and the complexity of your project.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drills\n",
    "\n",
    "- What was the hottest day in our data set? Where was that?\n",
    "\n",
    "\n",
    "- How many trips started at each station?\n",
    "\n",
    "\n",
    "- What's the shortest trip that happened?\n",
    "\n",
    "\n",
    "- What is the average trip duration, by end station?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joins and CTEs\n",
    "\n",
    "So far we've only worked with one table at a time. SQL easily allows us to combine multiple tables using a __JOIN__ clause.\n",
    "\n",
    "__Basic JOINS__\n",
    "When writing a join clause, indicate one or more pairs of columns. The two tables will then be joined when the value in each pair matches, returning rows with the data from both tables for every such case.\n",
    "\n",
    "By default, SQL will perform an __INNER JOIN__. The rows returned will have a successful join between the tables. If there is no match between the given columns, no rows will be returned.\n",
    "\n",
    "Let's try it on the BikeShare data and join the station and trip tables. Let's return the latitude and longitude of the starting station for each trip, along with the trip ID:\n",
    "\n",
    "    SELECT\n",
    "        trips.trip_id,\n",
    "        trips.start_station,\n",
    "        stations.lat,\n",
    "        stations.long\n",
    "    FROM\n",
    "        trips \n",
    "    JOIN\n",
    "        stations\n",
    "    ON\n",
    "        trips.start_station = stations.name;\n",
    "        \n",
    "Note that the __JOIN__ comes after the FROM statement. The two statements work together as you are selecting from both the initial table (trips table) and the joined table (stations table).\n",
    "\n",
    "In a two table join, the the order doesn't matter. But it's worth noting that the joins will happen in order, which can matter in more complex multi-table joins.\n",
    "\n",
    "In the above case, we're joining the start_station column of the trips table on the name column of the stations table. These two columns are how we join the trips table and the stations table into one composite table.\n",
    "\n",
    "Lastly, our __SELECT__ statement is choosing four columns from the composite (or \"joined\") table that we'd like to output: trip_id and start_station from the trips table, and lat & long from the stations table. We could use * here to select all columns from both tables if we wanted to. In practice, you almost always want to output specific parts of your join.\n",
    "\n",
    "__Table Aliases__\n",
    "We can rewrite the above query to utilize table aliasing:\n",
    "\n",
    "    SELECT\n",
    "        t.trip_id,\n",
    "        t.start_station,\n",
    "        s.lat,\n",
    "        s.long\n",
    "    FROM\n",
    "        trips t\n",
    "    JOIN\n",
    "        stations s\n",
    "    ON\n",
    "        t.start_station = s.name;\n",
    "\n",
    "Follow the tables in our __FROM__ and __JOIN__ statements with a space and then a single letter, then use this shorter name to refer to the tables in our select statement. \n",
    "\n",
    "You don't need to use aliases. You could use the actual table name as we did in the first example. However, aliases are very common and you'll see them a lot as you're reading other people's SQL code. No one agrees when you should or shouldn't use aliases. You should use them if it will make your code easier to read and maintain. You can also use them when joinging a table on itself and need two different aliases to refer to it.\n",
    "\n",
    "\n",
    "__Types of Joins__\n",
    "There a multiple ways to combine two tables. By default, SQL will perform an __inner join__ in which the only rows returned are ones with _both_ a match on the left table _and_ a match on the right table. Rows are only returned when there is a match on both sides, so it doesn't matter which table is on the left or which is on the right. SQL assumes you want an __inner join__ unless you specify differently, so using __JOIN__ is the same as using __INNER JOIN__.\n",
    "\n",
    "The others types of joins are __outer joins__: left outer joins, right outer joins, and full outer joins.\n",
    "\n",
    "In a __left outer join__ every row from the left table will be included in your output, _even if there is no matching row on the right table_. Tables are read like text, so the left table is the first table you specify and the right table the second specified. Rows without a match will be filled with __NULL__ for the columns on the right table. Left outer joins are often called \"left joins\" and you can perform them using __LEFT OUTER JOIN__ or __LEFT JOIN__.\n",
    "\n",
    "A __right outer join__ or \"right join\" is the same process as a left join, except all rows from the right table are returned--even if there's no match--and only rows with matching values are returned from the left table. You can perform a right join with __RIGHT OUTER JOIN__ or __RIGHT JOIN__.\n",
    "\n",
    "The only difference between a left join and right join is the order, so you can easily reverse the table order to complete a left or right join.\n",
    "\n",
    "\n",
    "A __full outer join__ or \"full join\" or \"outer join\" returns all matching records from _both_ left and right tables. This can potentially return a very large data set, enough to choke your laptop or even a production database serve.\n",
    "\n",
    "The default join in SQL is an inner join because they are much more common than outer joins. When you _do_ want to want to use an outer join, you'll usually end up using a left join.\n",
    "\n",
    "\n",
    "__Common Table Expressions__\n",
    "The result of every SQL query is itself a table. That means you can not only join tables on existing tables, you can also join tables on the result of a query. one way to do that is with __common table expressions__ or CTEs.\n",
    "\n",
    "There are two basic ways to use CTEs in SQL: step processing for queries (running a query that is too complex for a single execution and instead requires discrete steps) or preprocessing to facilitate a join.\n",
    "\n",
    "Let's try a preprocessing example. Recall that before we generated the average latitude and longitude of every city. What if we wanted to also included a count of the number of trips that started in each city? Doing this with a single query would look something like this:\n",
    "\n",
    "    SELECT\n",
    "        s.city,\n",
    "        AVG(s.lat) lat,\n",
    "        AVG(s.long) long,\n",
    "        COUNT(*)\n",
    "    FROM\n",
    "        stations s\n",
    "    JOIN\n",
    "        trips t\n",
    "    ON\n",
    "        t.start_station = s.name \n",
    "    GROUP BY 1;\n",
    "    \n",
    "_However_ this query is incorrect. When working with joins, the join happens _before_ any aggregate functions. So in the example above, we're actually taking the average of the latitude and longitude for every trip that occurred. So the results will skewed to the more popular station's coordinates. To do this properly we can use a CTE:\n",
    "\n",
    "CTEs start with the form\n",
    "    WITH __expression__ as (...)\n",
    "This will create an intermediate table for you to work with and join on. Let's rewrite the above query using a CTE:\n",
    "\n",
    "    -- Set up the CTE to create a \"locations\" table.\n",
    "    WITH\n",
    "        locations\n",
    "    AS (\n",
    "        -- A simple query to get the averages of lat and long on a city level.\n",
    "        SELECT\n",
    "            city,\n",
    "            AVG(lat) lat,\n",
    "            AVG(long) long\n",
    "        FROM\n",
    "            stations\n",
    "        GROUP BY 1\n",
    "    )\n",
    "\n",
    "    -- Joining the locations table we created with the trips table to count trips.\n",
    "    SELECT\n",
    "        l.city,\n",
    "        l.lat,\n",
    "        l.long,\n",
    "        COUNT(*)\n",
    "    FROM\n",
    "        locations l\n",
    "\n",
    "    -- We need an intermediate join to go from locations to stations \n",
    "    -- because the trips table does not have a \"city\" column.\n",
    "    JOIN\n",
    "        stations s\n",
    "    ON\n",
    "        l.city = s.city\n",
    "    JOIN\n",
    "        trips t\n",
    "    ON\n",
    "        t.start_station = s.name\n",
    "    GROUP BY 1,2,3;\n",
    "    \n",
    "Let's walk through how this query operates. First, the CTE creates a table LOCATIONS. This table groups stations by city name, then calculates the average latitude and longitude of those stations, giving the average station latitude and longitude per city. The LOCATIONS table is then joined with the TRIPS table.\n",
    "\n",
    "But we can't directly join LOCATIONS onto the TRIPS table, because LOCATIONS has a city column and the TRIPS table doesn't. We must first join LOCATIONS back on the STATIONS table--which has a city column--then join STATIONS onto the TRIPS table on the common start_station and station name columns. It's common to use multiple joins like this to relate two tables you can't join directly.\n",
    "\n",
    "All of this comes together to give the average latitude, longitude, and count of the number of trips per city.\n",
    "\n",
    "\n",
    "__Case Statements__\n",
    "__CASE__ statements allow you to set up conditions and then take action in a column based on them. It's common to combine __CASE__ statements with __COUNT__ to do conditional counts. Here's an example of the most common form of case statements:\n",
    "    CASE WHEN __condition__ THEN __value__ ELSE __value__ END\n",
    "\n",
    "Let's see an example of a __CASE__ statement:\n",
    "\n",
    "    SELECT\n",
    "        (CASE WHEN dockcount > 20 THEN 'large' ELSE 'small' END) station_size,\n",
    "        COUNT(*) as station_count\n",
    "    FROM \n",
    "        stations\n",
    "    GROUP BY 1;\n",
    "    \n",
    "This __CASE__ statement looks at the STATIONS table and labels each row either 'large' or 'small' depending on the value of dockcount for that row. The __CASE__ statement then counts how many rows there are for each case. The __GROUP BY__ statement allows us to count based on station size.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DRILLS\n",
    "\n",
    "- What are the three longest trips on rainy days?\n",
    "\n",
    "\n",
    "- Which station is full most often?\n",
    "\n",
    "\n",
    "- Return a list of stations with a count of number of trips starting at that station but ordered by dock count.\n",
    "\n",
    "\n",
    "(Challenge) What's the length of the longest trip for each day it rains anywhere?\n",
    "\n",
    "\n",
    "__Queries running a little slow?__ This is a large database for working locally, particularly the status table. It may be helpful to create a smaller version of the status table to help develop these queries so things run faster and you can iterate easily.\n",
    "\n",
    "Try running something like:\n",
    "\n",
    "    CREATE TABLE status_abbreviated AS\n",
    "      SELECT *\n",
    "      FROM status\n",
    "      limit 10000;\n",
    "      \n",
    "This will create a table with only 10,000 entries from status, making for faster joins and queries. When you think your query is running properly test it against the full table to confirm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now be familiar with writing basic SQL. Queries can range from a few simple lines to literally hundreds with complicated joins and cases.We covered the basics of setting up a Postgres database, as well as some of the basics of querying like __SELECT__, __GROUP BY__, and __JOIN__. Remember there are several forms of SQL, and while they share a basic structure, there will be differences. When working with a database, it's always good to look up some of the functions and structure of the particular type of SQL you're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
