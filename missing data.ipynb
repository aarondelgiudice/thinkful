{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Data\n",
    "\n",
    "Unit 1 / Lesson 3 / Assignment 7\n",
    "\n",
    "Most datasets will how at least some missing values. Cleaning the dataset can even increase the number of missing values.\n",
    "\n",
    "Even if missingness is random, it can still cause difficulties during analysis. The basic `Python` statistical methods like `ANOVA`, `t-tests`, and `correlations` will fail if there are any missing values in the variables involved in those calculations.\n",
    "\n",
    "One solution is to use the `Pandas` package `dropna()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age gender  height  weight\n",
      "0  27.0      f    64.0   140.0\n",
      "1  50.0      f     NaN     NaN\n",
      "2  34.0      f    71.0   130.0\n",
      "3   NaN      m    66.0   110.0\n",
      "4   NaN      m    68.0   160.0\n",
      "5   NaN   None     NaN     NaN\n",
      "    age gender  height  weight\n",
      "0  27.0      f    64.0   140.0\n",
      "2  34.0      f    71.0   130.0\n",
      "    age gender  height  weight\n",
      "0  27.0      f    64.0   140.0\n",
      "1  50.0      f     NaN     NaN\n",
      "2  34.0      f    71.0   130.0\n",
      "3   NaN      m    66.0   110.0\n",
      "4   NaN      m    68.0   160.0\n",
      "    age gender  height  weight\n",
      "0  27.0      f    64.0   140.0\n",
      "1  50.0      f     NaN     NaN\n",
      "2  34.0      f    71.0   130.0\n",
      "3   NaN      m    66.0   110.0\n",
      "4   NaN      m    68.0   160.0\n",
      "    age gender  height  weight\n",
      "0  27.0      f    64.0   140.0\n",
      "2  34.0      f    71.0   130.0\n",
      "3   NaN      m    66.0   110.0\n",
      "4   NaN      m    68.0   160.0\n",
      "    age gender  height  weight\n",
      "0  27.0      f    64.0   140.0\n",
      "2  34.0      f    71.0   130.0\n",
      "3   NaN      m    66.0   110.0\n",
      "4   NaN      m    68.0   160.0\n"
     ]
    }
   ],
   "source": [
    "# sample data\n",
    "data = {\n",
    "    'age': [27, 50, 34, None, None, None],\n",
    "    'gender': ['f', 'f', 'f', 'm', 'm', None],\n",
    "    'height' : [64, None, 71, 66, 68, None],\n",
    "    'weight' : [140, None, 130, 110, 160, None],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# view data\n",
    "print(df)\n",
    "\n",
    "# drop all rows with missing values in any column\n",
    "print(df.dropna())\n",
    "\n",
    "# drop only rows where all values are missing\n",
    "print(df.dropna(how='all'))\n",
    "\n",
    "# drop only rows with two or more values missing\n",
    "print(df.dropna(thresh=2))\n",
    "\n",
    "# drop only rows that have missing values in the 'gender' or 'height' column\n",
    "print(df.dropna(subset=['gender','height']))\n",
    "\n",
    "# drop only rows that have missing values in both the 'height' and 'weight' column\n",
    "print(df.dropna(how='any', subset=['height', 'weight']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When does missingness matter?\n",
    "\n",
    "Sometimes dropping all rows with missing data is fine, sometimes it will create more problems.\n",
    "Missing data matters when we believe the missingness will cause:\n",
    "- loss of analytical relevance because so many rows had to be dropped\n",
    "- bias because certain values are more likely to be missing than others\n",
    "\n",
    "To help understand when to drop missing data and when not to, determine where the missing data falls in the following categories:\n",
    "\n",
    "__Missing Completely at Random (MCaR)__:\n",
    "Damaged equipment caused a loss of 20% of all data. In this case, the missingness is tolerable.\n",
    "Unless the loss of data is so much that our sample size is now too small, we can throw out the missing data.\n",
    "\n",
    "__Missing at Random (MaR)__:\n",
    "Women are more likely to skip questions about weight, lower-income individuals are more likely to skip questions about earnings, people who consume high amounts of alcohol each week are more likely to skip questions about alcoholic consumption.\n",
    "If we can explain why this data is missing use the data we already have, we can proceed without the data.\n",
    "Though we must include the variable that 'explains' the missingness in our analysis.\n",
    "There is no way to know completely if data is __MaR__, but sometimes it's safe to assume it is.\n",
    "If we find a variable during our analysis that seems to have a clear differentiation between missing and non-missing values (for example 90% of missing entries from a mental wellness survey are from males), we can reasonably suspect __MaR__.\n",
    "\n",
    "__Missing Not at Random (MNaR)__:\n",
    "Data that appears to have systematic missingness can be classified as __MNaR__.\n",
    "This type of data can not be thrown out as we will end up with a biased sample and biased conclusions.\n",
    "An instance of __MNaR__ data would be would be people who would answer a survey question a certain way may not answer the questions at all.\n",
    "\n",
    "\n",
    "For example, people out of work might be less likely to answer a survey question about unemployment.\n",
    "In that case our analysis would show proportionately fewer unemployed people in a population than there truly are.\n",
    "Since we can't know what __MNaR__ data would be, we can only at best make an assumption by looking for what's not in the data.\n",
    "Abnormally low counts of reported homelessness, fewer LGBTQ people in a population than expected, 90% of questions about mental wellness left blank by male survey-takers, variables with missingness where no one picks the highest and lowest values.\n",
    "\n",
    "\n",
    "### Imputation\n",
    "What do you do when you have missing data that you can't drop, or doing so would leave your sample too small?\n",
    "We can \"guess\" what the missing data would have been and use a `fill` method to input that data.\n",
    "This process is called `imputation`.\n",
    "\n",
    "In most cases, `imputation` involves replacing missing values with some kind of statistical measure--the mean, median, or mode--of the variable.\n",
    "This method isn't perfect, but it preserves central tendancy at the cost of reducing variance and correlations among variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age gender  height  weight\n",
      "0  27.0      f    64.0   140.0\n",
      "1  50.0      f     NaN     NaN\n",
      "2  34.0      f    71.0   130.0\n",
      "3   NaN      m    66.0   110.0\n",
      "4   NaN      m    68.0   160.0\n",
      "5   NaN   None     NaN     NaN \n",
      "\n",
      "    age gender  height  weight\n",
      "0  27.0      f   64.00   140.0\n",
      "1  50.0      f   67.25   135.0\n",
      "2  34.0      f   71.00   130.0\n",
      "3  37.0      m   66.00   110.0\n",
      "4  37.0      m   68.00   160.0\n",
      "5  37.0   None   67.25   135.0 \n",
      "\n",
      "    age gender  height  weight\n",
      "0  27.0      f    64.0   140.0\n",
      "1  50.0      f    68.0   160.0\n",
      "2  34.0      f    71.0   130.0\n",
      "3  34.0      m    66.0   110.0\n",
      "4  34.0      m    68.0   160.0\n",
      "5  34.0      f    68.0   160.0 \n",
      "\n",
      "    age gender  height  weight\n",
      "0  27.0      f    64.0   140.0\n",
      "1  50.0      f    67.0   135.0\n",
      "2  34.0      f    71.0   130.0\n",
      "3  37.0      m    66.0   110.0\n",
      "4  37.0      m    68.0   160.0\n",
      "5  37.0      f    67.0   135.0\n"
     ]
    }
   ],
   "source": [
    "# Sample data to play with.\n",
    "data = {\n",
    "    'age': [27, 50, 34, None, None, None],\n",
    "    'gender': ['f', 'f', 'f', 'm', 'm', None],\n",
    "    'height' : [64, None, 71, 66, 68, None],\n",
    "    'weight' : [140, None, 130, 110, 160, None],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df, '\\n')\n",
    "\n",
    "# For each numeric column, replace the missing values with the mean for that column\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "print(df, '\\n')\n",
    "\n",
    "# For each column, replace the missing values with the most common value for that column.\n",
    "# This is useful for filling in missing categorical values.\n",
    "# As written, this command will fill in missing values for both numerical and categorical columns.\n",
    "df = pd.DataFrame(data)\n",
    "df = df.apply(lambda x: x.fillna(x.value_counts().index[0]))\n",
    "\n",
    "print(df, '\\n')\n",
    "\n",
    "# for each column, replace each missing value with the median, mode, or another statistic of your choice.\n",
    "df = pd.DataFrame(data)\n",
    "# replace missing 'age' values with the average value\n",
    "df['age'].fillna(df['age'].mean(), inplace=True)\n",
    "# replace missing 'gender' values with the most common value\n",
    "df['gender'] = df['gender'].fillna(df['gender'].value_counts().index[0])\n",
    "# replace missing 'height' and 'weight' values with medians values\n",
    "df['height'].fillna(df['height'].median(), inplace=True)\n",
    "df['weight'].fillna(df['weight'].median(), inplace=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proper __imputation__ is a complex topic. A more sophisticated method than the one we used above, would be grouping existing data entries in categories based on similarities.\n",
    "Then we can subset the data with those groups and perform statistical measures specific to those groups to fill in the missing data.\n",
    "For more information, check out his [imputation tutuorial](https://www.analyticsvidhya.com/blog/2014/09/data-munging-python-using-pandas-baby-steps-python/)\n",
    "\n",
    "### Beyond Imputation\n",
    "If the cause of missing data is an easy fix, then collection new data may be the simplest option to replace the missing data rather than imputating data.\n",
    "Either run the study again, refresh the API, or collect more data with a focus on the groups with the highest instances of missingness.\n",
    "For example, a coding error in a survey means data wasn't recorded for any Mac users, it may be easier to fix the coding error and run the study again (or fix the coding error and collect data from just Mac users) than try to impute such a centrally important variable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
